{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corporate FinTech Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name and e-mail"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mads Duelund Dorka, mador17@student.sdu.dk\n",
    "\n",
    "Max Festersen Hansen, maxfh20@student.sdu.dk\n",
    "\n",
    "Mathias Eriksen, merik17@student.sdu.dk\n",
    "\n",
    "Daniel Lindberg, dlind16@student.sdu.dk\n",
    "\n",
    "Emilie Bruun Therp, emthe15@student.sdu.dk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint # To print \"stuff\" pretty\n",
    "import pandas as pd # To work with dataframes and math functions\n",
    "import numpy as np # to work with math\n",
    "import statsmodels.api as sm # To use OLS\n",
    "import json # To work with json files\n",
    "from textblob import TextBlob # To do Naïve Bayes classifification\n",
    "from textblob.classifiers import NaiveBayesClassifier\n",
    "from datetime import datetime # To format strings as dates\n",
    "import textstat # To get fog gunning values\n",
    "#from matplotlib.pylab import plt # To plot plots\n",
    "#from sklearn.linear_model import LogisticRegression\n",
    "#from sklearn.metrics import classification_report, confusion_matrix\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enviroment and Data imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "filename = 'icoData_19092018.json'\n",
    "with open(filename) as json_data:\n",
    "    icoData = json.load(json_data) #Load data into a list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formatting data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "icoData = [x for x in icoData if not len(x) == 1]  # Filter list - remove empty dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "icoDataFiltPersonNum = [] # For person instance\n",
    "icoDataFiltReview = [] # For reviews\n",
    "icoDataFiltReviewNum = [] # For a unique identifier for reviews\n",
    "icoDataFiltTeamRating = [] # The team rating;\n",
    "icoDataFiltVisionRating = [] # The vision rating;\n",
    "icoDataFiltProductRating = [] # The product rating;\n",
    "icoDataFiltOverallRating = [] # Overall rating;\n",
    "icoDataFiltAmountRaised = [] # Amount raised;\n",
    "icoDataFiltSuccess = [] # Successes\n",
    "\n",
    "i = 0\n",
    "personNum = 0\n",
    "reviewNum = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loop all of icoData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for person in icoData:\n",
    "    personNum += 1 # Count next person\n",
    "    # Filter end-dates after 19-10-2018\n",
    "    endDate = person['dates'][\"icoEnd\"].split(\" \")[0]\n",
    "    if endDate != '0000-00-00' and datetime.strptime(endDate, \"%Y-%m-%d\") < datetime.strptime(\"2018-10-19\", \"%Y-%m-%d\"):\n",
    "        validDate = True # If the date is a valid date, and before 2018-10-19\n",
    "    else:\n",
    "        validDate = False\n",
    "    if validDate:\n",
    "        for rating in person['ratings']:\n",
    "            if \"review\" in rating and len(rating[\"review\"]) > 0:\n",
    "                reviewNum += 1 # Count valid review\n",
    "                # Save ratings review instance\n",
    "                icoDataFiltPersonNum.append(personNum) # Person number for data validation\n",
    "                icoDataFiltReviewNum.append(reviewNum) # Review number as uniqe classification\n",
    "                icoDataFiltReview.append(rating['review']) # Review used in Exercise 2a-d and Exercise 3 part 1-3\n",
    "                icoDataFiltTeamRating.append(rating[\"team\"]) # Team rating from review\n",
    "                icoDataFiltVisionRating.append(rating[\"vision\"]) # Vision rating from review\n",
    "                icoDataFiltProductRating.append(rating[\"product\"]) # Product rating from review\n",
    "                icoDataFiltOverallRating.append(person[\"rating\"]) # Overall rating from person (NOTE: NOT REVIEW LEVEL)\n",
    "                amountRaised = person[\"finance\"][\"raised\"] # Amount raised\n",
    "                icoDataFiltAmountRaised.append(amountRaised) # Append amount raised\n",
    "                icoDataFiltSuccess.append(1 if amountRaised > 0 else 0) # Success (= dummy (1) if amount raised larger 0).\n",
    "    i+=1 # Increment instance counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Format as dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDt = pd.DataFrame({   '#review': icoDataFiltReviewNum,\n",
    "                            'Person ID': icoDataFiltPersonNum,\n",
    "                            'Review':icoDataFiltReview,\n",
    "                            'Team rating':icoDataFiltTeamRating,\n",
    "                            'Vision rating':icoDataFiltVisionRating,\n",
    "                            'Product rating':icoDataFiltProductRating,\n",
    "                            'Overall Rating':icoDataFiltOverallRating,\n",
    "                            'Amount Raised':icoDataFiltAmountRaised,\n",
    "                            'Success':icoDataFiltSuccess\n",
    "                         })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Natural language processing is a concept where the automated generation and understanding of natural human languages are studied. The concept of readability is how a reader can understand a written text, moreover how hard or easy a text is to read. The readability measures depend on various “variables” i.e. Complexity of the words, the syntax, or the length of the sentences, depending on which model you are using. In the end, you get a value, which tells the reader how hard the text is to read.\n",
    "\n",
    "One way to measure, the readability measure is by the Fog index. When using the Fog index, the test aims to show the reader the difficulty level of the text. The level/index refers to the number of years of education a person needs to have to fully understand the text on the first reading.\n",
    " \n",
    " \n",
    "To calculate the Fog index, the following components must be known.\n",
    "-    Average sentence length, percentage of long words and the sum of average sentence length and the percentage of long words.\n",
    " \n",
    "However, when checking for long words, there are some exceptions i.e.Company names, combines short-words and short three-syllable words.\n",
    "\n",
    "When writing in business language, you should aim for a score around 20-25, and in an office report a score of 30-35. NLP is used more than ever in financial research. Financial firms are using the NLP to parse textual data. Instead of having employees to check the textual data, the NLP are faster and more accurate than humans are. When using the NLP, companies are able to filter and analyze data faster. This allows companies to follow their stocks very closely and sell them if they discover that the company is budgeting with a loss in their earnings report.\n",
    " \n",
    "NLP can improve decision-making and speed inside financial organizations with three instances. Automation, Data enrichment, and Search and discovery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Median and 50% quartile is effectivly the same. We asume that the exercise needs 75% quartile instead of a redundant median. This assumtion is applicable for all of the assignment.\n",
    "\n",
    "\n",
    "Mean:\n",
    "\n",
    "We would expect the mean to be around zero, as we would expect approximately the same amount of positive and negative words. However, given the type of data, and that people often are positive when it comes to new projects, one could argue that the mean probably is leaning to the positive side.\n",
    "\n",
    "\n",
    "Minimum and maximum:\n",
    "\n",
    "Initially we would expect the minimum value to be -1 and the maximum value to 1, however as seen in class, it is quite unusual to see a negative word valued -1, hence one might expect it to be a little larger.\n",
    "\n",
    "25%:\n",
    "\n",
    "We would expect the 25th quantile to be negative, as we would argue that there would be a minimum of 25% negative comments.\n",
    "\n",
    "\n",
    "50% / Median:\n",
    "\n",
    "As argued above, we would expect the median to be slightly above 0, as we would expect people to have a positive and open mind when it comes to new projects.\n",
    "\n",
    "\n",
    "75%:\n",
    "\n",
    "We would expect the 75th quantile to be around 0.3-0.5, as we would expect more positively weighted words, however we would argue that people rarely use words which are extremely positive, and hence weighted as 1. People are more likely to use less weighted positive words, even in extremely positive cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math calculater  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Describe funktionen from pandas is used to return a overview containing count, mean, standard deviation, minimim value, 25%, median, 75% og maximum value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the polarity score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimetsPolarity = []\n",
    "sentimetsSubjectivity = []\n",
    "for review in icoDataFiltReview: # For every review in the filtered reviews\n",
    "    tb = TextBlob(review) # Peform sentiment analasys\n",
    "    sentimetsPolarity.append(tb.sentiment[0]) # Get polarity score\n",
    "    sentimetsSubjectivity.append(tb.sentiment[1]) # Get subjectivity score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add to dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDt[\"Polarity\"] = sentimetsPolarity\n",
    "reviewDt[\"Subjectivity\"] = sentimetsSubjectivity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDtSemanticInfo = reviewDt[['Polarity']].describe()\n",
    "#median = reviewDt[['Polarity']].median()\n",
    "#reviewDtSemanticInfo = reviewDtSemanticInfo.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Polarity\n",
      "count  5483.000000\n",
      "mean      0.300281\n",
      "std       0.267197\n",
      "min      -0.700000\n",
      "25%       0.118803\n",
      "50%       0.265714\n",
      "75%       0.466667\n",
      "max       1.000000\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(reviewDtSemanticInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation /discussion of economic aspects of the result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mean:\n",
    "\n",
    "We calculated a mean of 0.3, which shows that people tend to be more positive in the data. This is in compliance with what we discussed in the expectations, namely the fact that people tend to lean to the positive side when it comes to new projects.\n",
    "\n",
    "\n",
    "Minimum and maximum:\n",
    "\n",
    "We see a minimum of -0.7 and a maximum of 1. This is not in compliance with the initial thought, however it does fit what we have seen in class, with very few negative words actually being weighted as -1-\n",
    "\n",
    "\n",
    "25%:\n",
    "\n",
    "We see that the 25th quantile for the data is 0.1188, this is not what we expected. This deems to show that people tend to write fewer negative words than what we would expect. However, this is in compliance with what we mentioned above, with people tending to be more positive about startups.\n",
    "\n",
    "\n",
    "50% / Median:\n",
    "\n",
    "Same logic as with the 25th quantile. We expected the median to be slightly lower than the 0.2657 that we found. However, this might be reasoned by people being more positive about startups.\n",
    "\n",
    "\n",
    "75%:\n",
    "\n",
    "The 75th quantile is in compliance with what we initially thought. It is in the high end of what was expected, but nonetheless in compliance. This does make quite good sense, as people aren’t that likely to use very heavily weighted positive words, but instead opts for less heavily weighted words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expectation section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect that the Fog index will be in the high end of the scale. This is because it is mostly university employees, professors, and people trading with crypto currencies that reads and comments on these projects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math calculator "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fog Index = 0.4 *(average # of words per sentence + 100 * percent of complex words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get Fog gunning values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fogValues = []\n",
    "for review in icoDataFiltReview: # For every review in the filtered reviews\n",
    "    fogValues.append(textstat.gunning_fog(review)) # Get and append fog index for review"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add to dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDt[\"Fog Index\"] = fogValues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDtFogInfo = reviewDt[['Fog Index']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Fog Index\n",
      "count  5483.000000\n",
      "mean     11.983903\n",
      "std       9.750480\n",
      "min       0.000000\n",
      "25%       7.315000\n",
      "50%      10.340000\n",
      "75%      14.640000\n",
      "max     156.910000\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(reviewDtFogInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation /discussion of economic aspects of the result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relevant results shows the opposite of what we expected. When calculating the Fog index, we see that the mean is around 12. From the results, we also see that the 50% quantile is lower than the mean. From this, we can see that reviews about the median are a lot higher than the median, which also visible when looking at max.\n",
    "\n",
    "\n",
    "However, when looking at the results it does make sense that the Fog index is low. This could be explained by the fact that the given text is short reviews. Reviews tend to be short and simple, making it easy to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Expectation section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect that the overall rating will have a positive correlation between amount raised and the success of the project. However, we do not expect that the other variables correlate. The rating variables will most likely be more correlated than the other variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Math calculater "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correlation matrix measure of the linear association between two variables. It has a value between -1 and 1 where:\n",
    "\n",
    "•    -1 indicates a perfectly negative linear correlation between two variables\n",
    "\n",
    "•    0 indicates no linear correlation between two variables\n",
    "\n",
    "•    1 indicates a perfectly positive linear correlation between two variables\n",
    "\n",
    "\n",
    "The further away the correlation coefficient is from zero, the stronger the relationship between the two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "corr function from pandas is used on the datasetet to create a correlation matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Execution of task "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Polarity  Fog Index  Team rating  Vision rating  \\\n",
      "Polarity        1.000000  -0.224758     0.420646       0.442749   \n",
      "Fog Index      -0.224758   1.000000    -0.096129      -0.097844   \n",
      "Team rating     0.420646  -0.096129     1.000000       0.756970   \n",
      "Vision rating   0.442749  -0.097844     0.756970       1.000000   \n",
      "Product rating  0.444003  -0.132969     0.764593       0.822642   \n",
      "Overall Rating  0.312247  -0.013937     0.676591       0.631365   \n",
      "Amount Raised   0.009342   0.083689     0.036685       0.039661   \n",
      "Success         0.115465  -0.039221     0.184371       0.166338   \n",
      "\n",
      "                Product rating  Overall Rating  Amount Raised   Success  \n",
      "Polarity              0.444003        0.312247       0.009342  0.115465  \n",
      "Fog Index            -0.132969       -0.013937       0.083689 -0.039221  \n",
      "Team rating           0.764593        0.676591       0.036685  0.184371  \n",
      "Vision rating         0.822642        0.631365       0.039661  0.166338  \n",
      "Product rating        1.000000        0.625884       0.035279  0.155515  \n",
      "Overall Rating        0.625884        1.000000       0.035678  0.224564  \n",
      "Amount Raised         0.035279        0.035678       1.000000  0.093845  \n",
      "Success               0.155515        0.224564       0.093845  1.000000  \n"
     ]
    }
   ],
   "source": [
    "corrMatrix = reviewDt[['Polarity',\n",
    "                       'Fog Index',\n",
    "                       'Team rating',\n",
    "                       'Vision rating',\n",
    "                       'Product rating',\n",
    "                       'Overall Rating',\n",
    "                       'Amount Raised',\n",
    "                       'Success']].corr()\n",
    "                         # Missing from data: the team rating; the vision rating; the product rating; overall rating; amount raised; success (= dummy (1) if amount raised larger 0).\n",
    "pprint.pprint(corrMatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation /discussion of economic aspects of the result "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The correlation between Fog index, and everything but the amount raised is negative. This does intuitively make sense, as a high Fog index would make for more complicated reading, and hence you could assume that if the Fog index is high, less people would be able to actually use the text, and hence it would be rated lesser.\n",
    "\n",
    "However, people with a higher degree, might be able to invest more money, and hence it might make sense that there is a positive correlation here. Polarity generally has a positive correlation to the other variable, except fog index.\n",
    "\n",
    "\n",
    "Overall rating has a positive correlation to success. Then the overall rating increases, then there is a greater chance that the project will be successful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### i) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expectation section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary least square regression estimates the relationship between one or more independent variables and a dependent variable by minimizing the sum of the squares in the difference between the observed and the predicted values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run an OLS regression of the amount raised on polarity score. Fog index, the team rating, the vision rating, the product rating. Overall rating. Interpret your results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLS Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ols_amountRaisedOn(X): # Give predictor value - does ols with amount raised as predictor - returns fitted ols estimate\n",
    "    X = sm.add_constant(X) # add constant to predictor\n",
    "    y = reviewDt[[\"Amount Raised\"]] # response value\n",
    "    est = sm.OLS(y, X) # Create model from response, y and predictor X\n",
    "    est = est.fit() # fitting model\n",
    "    #X_prime = np.linspace(X.iloc[:, 1].min(), X.iloc[:, 1].max(), 100)[:, np.newaxis]\n",
    "    #X_prime = sm.add_constant(X_prime) \n",
    "    #y_hat = est.predict(X_prime)\n",
    "    #fig = plt.xlabel(\"Amount Raised\") \n",
    "    #fig = plt.ylabel(X.columns[1]) \n",
    "    #fig = plt.plot(X_prime[:, 1], y_hat, 'r', alpha=0.9)\n",
    "    #plt.show()\n",
    "    return est.summary() # return params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### OLS:  Amount raised on polarity score, fog index, the team rating, the vision rating, the product rating, overall rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'statsmodels.iolib.summary.Summary'>\n",
      "\"\"\"\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:          Amount Raised   R-squared:                       0.010\n",
      "Model:                            OLS   Adj. R-squared:                  0.009\n",
      "Method:                 Least Squares   F-statistic:                     8.854\n",
      "Date:                Sun, 21 Mar 2021   Prob (F-statistic):           1.24e-09\n",
      "Time:                        23:35:34   Log-Likelihood:            -1.0768e+05\n",
      "No. Observations:                5483   AIC:                         2.154e+05\n",
      "Df Residuals:                    5476   BIC:                         2.154e+05\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==================================================================================\n",
      "                     coef    std err          t      P>|t|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "const          -1.328e+07      6e+06     -2.212      0.027    -2.5e+07   -1.51e+06\n",
      "Polarity        2.255e+06   4.78e+06      0.472      0.637   -7.12e+06    1.16e+07\n",
      "Fog Index       7.637e+05   1.17e+05      6.527      0.000    5.34e+05    9.93e+05\n",
      "Team rating     8.506e+05   1.63e+06      0.522      0.601   -2.34e+06    4.04e+06\n",
      "Vision rating    1.43e+06   1.69e+06      0.848      0.397   -1.88e+06    4.74e+06\n",
      "Product rating  9.375e+05   1.67e+06      0.560      0.576   -2.35e+06    4.22e+06\n",
      "Overall Rating   3.83e+05   2.14e+06      0.179      0.858   -3.82e+06    4.58e+06\n",
      "==============================================================================\n",
      "Omnibus:                    17049.306   Durbin-Watson:                   0.996\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):       1348651167.877\n",
      "Skew:                          47.964   Prob(JB):                         0.00\n",
      "Kurtosis:                    2430.770   Cond. No.                         93.3\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "\"\"\"\n"
     ]
    }
   ],
   "source": [
    "olsResult = ols_amountRaisedOn(reviewDt[[\"Polarity\", \"Fog Index\",\"Team rating\", \"Vision rating\", \"Product rating\", \"Overall Rating\"]])\n",
    "pprint.pprint(olsResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation /discussion of economic aspects of the result. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the OLS regression we see that the Fog Index has a P-value of 0.000, hence we reject the impact of the Fog value on the amount raised. We see that the other variables are statistically significant on a 95% significance level for the amount raised. \n",
    "\n",
    "This does intuitively make sense, as Fog index only explains the difficulty of the text, and not wether it is positively or negatively weighted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ii)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic regression\n",
    "#### Expectation section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the logit regression, we can reject everything but the be vision rating and the product rating on a 95% significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.640781\n",
      "         Iterations 5\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                Success   No. Observations:                 5483\n",
      "Model:                          Logit   Df Residuals:                     5477\n",
      "Method:                           MLE   Df Model:                            5\n",
      "Date:                Sun, 21 Mar 2021   Pseudo R-squ.:                 0.02351\n",
      "Time:                        23:35:36   Log-Likelihood:                -3513.4\n",
      "converged:                       True   LL-Null:                       -3598.0\n",
      "Covariance Type:            nonrobust   LLR p-value:                 1.079e-34\n",
      "==================================================================================\n",
      "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
      "----------------------------------------------------------------------------------\n",
      "Polarity           0.3473      0.125      2.783      0.005       0.103       0.592\n",
      "Fog Index         -0.0129      0.003     -4.407      0.000      -0.019      -0.007\n",
      "Team rating        0.0934      0.042      2.249      0.025       0.012       0.175\n",
      "Vision rating      0.0163      0.043      0.377      0.706      -0.068       0.101\n",
      "Product rating    -0.0372      0.043     -0.866      0.386      -0.122       0.047\n",
      "Overall Rating     0.1003      0.039      2.588      0.010       0.024       0.176\n",
      "==================================================================================\n"
     ]
    }
   ],
   "source": [
    "x = reviewDt[[\"Polarity\", \"Fog Index\",\"Team rating\", \"Vision rating\", \"Product rating\", \"Overall Rating\"]]\n",
    "y = reviewDt[\"Success\"]\n",
    "model = sm.Logit(y,x)\n",
    "result=model.fit()\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation /discussion of economic aspects of the result.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hence, we see that vision rating and product rating seems to be the only relevant factors for success, however all but Fog index are relevant for the amount raised."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expectation section "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the results from randomly selected data from our own classifiers result to be similar to the result from Textblob, but we do expect our trained data to be more precice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### part 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting 150 random reviews "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDtSample = reviewDt.sample(n=150, random_state=666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### reviewDtSample[\"n\"] =   range(150) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDtSample[\"class\"]=[\"negative\", \"negative\", \"neutral\", \"neutral\", \"positive\", \"positive\", \"negative\", \"neutral\", \"negative\", \"positive\", \"positive\", \"neutral\", \"positive\", \"neutral\", \"negative\", \"neutral\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"negative\", \"positive\", \"neutral\", \"neutral\", \"negative\", \"positive\", \"positive\", \"positive\", \"neutral\", \"neutral\", \"positive\", \"positive\", \"positive\", \"neutral\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"neutral\", \"positive\", \"negative\", \"neutral\", \"positive\", \"negative\", \"negative\", \"positive\", \"positive\", \"positive\", \"neutral\", \"positive\", \"positive\", \"positive\", \"negative\", \"negative\", \"positive\", \"neutral\", \"negative\", \"positive\", \"negative\", \"positive\", \"positive\", \"positive\", \"negative\", \"positive\", \"negative\", \"positive\", \"positive\", \"neutral\", \"positive\", \"positive\", \"positive\", \"neutral\", \"neutral\", \"positive\", \"neutral\", \"negative\", \"positive\", \"negative\", \"neutral\", \"negative\", \"negative\", \"negative\", \"positive\", \"negative\", \"positive\", \"positive\", \"positive\", \"negative\", \"neutral\", \"positive\", \"positive\", \"positive\", \"positive\", \"neutral\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"negative\", \"neutral\", \"negative\", \"positive\", \"positive\", \"positive\", \"positive\", \"negative\", \"positive\", \"positive\", \"positive\", \"negative\", \"positive\", \"negative\", \"negative\", \"negative\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"negative\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"positive\", \"negative\", \"negative\", \"negative\", \"positive\", \"positive\", \"positive\", \"negative\", \"positive\", \"neutral\", \"positive\", \"positive\", \"positive\", \"negative\", \"positive\", \"neutral\", \"positive\", \"positive\" ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDtSampleTraining = reviewDtSample.iloc[0:99].copy(deep=False)\n",
    "reviewDtSampleTest = reviewDtSample.iloc[100:149].copy(deep=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train classifier using textblob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = NaiveBayesClassifier(reviewDtSampleTraining[[\"Review\", \"class\"]].values.tolist()) # Train on training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test on testdata "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDtSampleTests = []\n",
    "\n",
    "for review in reviewDtSampleTest[\"Review\"].values:\n",
    "    reviewDtSampleTests.append(cl.classify(review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDtSampleTest.__setitem__('classCl', reviewDtSampleTests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDtClaccuracy = np.where(reviewDtSampleTest[\"classCl\"] == reviewDtSampleTest[\"class\"], 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDtClaccuracyPercent = sum(reviewDtClaccuracy)/len(reviewDtClaccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation /discussion of economic aspects of the result.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracy of the trained model is:  65.31 %.\n",
    "\n",
    "The accuracy of the training model is relatively low. This could be due the complexity of the reviews posibly has caused human error and a machine with confusing instructions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate the polarity score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentimetsPolarityCl = []\n",
    "sentimetsSubjectivityCl = []\n",
    "for review in icoDataFiltReview: # For every review in the filtered reviews\n",
    "    tb = TextBlob(review, classifier=cl) # Peform sentiment analasys\n",
    "    sentimetsPolarityCl.append(tb.sentiment[0]) # Get polarity score\n",
    "    sentimetsSubjectivityCl.append(tb.sentiment[1]) # Get subjectivity score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add to dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDt[\"PolarityCL\"] = sentimetsPolarityCl\n",
    "reviewDt[\"SubjectivityCL\"] = sentimetsSubjectivityCl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analyzis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviewDtCLSemanticInfo = reviewDt[['PolarityCL']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PolarityCL\n",
      "count  5483.000000\n",
      "mean      0.300281\n",
      "std       0.267197\n",
      "min      -0.700000\n",
      "25%       0.118803\n",
      "50%       0.265714\n",
      "75%       0.466667\n",
      "max       1.000000\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(reviewDtCLSemanticInfo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interpretation /discussion of economic aspects of the result.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The polarity scores with with our classifier are exactly the same as Textblob's classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
